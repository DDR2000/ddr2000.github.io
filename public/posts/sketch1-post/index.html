<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Sketch1 Post | </title>
<meta name="keywords" content="">
<meta name="description" content="To absolutely no one&rsquo;s surprise I didn&rsquo;t actually go through with updating this page regularly. The good news is I&rsquo;ve been keeping busy with projects.
One of those projects is what I&rsquo;m very creatively calling SketchTo3D. The idea is fairly simple, but we&rsquo;ll talk about the main motivation behind this project in a bit. Let&rsquo;s first look at an example input.
The goal is to turn drawings like this one into a 3D mesh, while somehow retaining depth information.">
<meta name="author" content="">
<link rel="canonical" href="https://ddr2000.github.io/posts/sketch1-post/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.4599eadb9eb2ad3d0a8d6827b41a8fda8f2f4af226b63466c09c5fddbc8706b7.css" integrity="sha256-RZnq256yrT0KjWgntBqP2o8vSvImtjRmwJxf3byHBrc=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://ddr2000.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://ddr2000.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://ddr2000.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://ddr2000.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://ddr2000.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://ddr2000.github.io/posts/sketch1-post/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
  

<meta property="og:title" content="Sketch1 Post" />
<meta property="og:description" content="To absolutely no one&rsquo;s surprise I didn&rsquo;t actually go through with updating this page regularly. The good news is I&rsquo;ve been keeping busy with projects.
One of those projects is what I&rsquo;m very creatively calling SketchTo3D. The idea is fairly simple, but we&rsquo;ll talk about the main motivation behind this project in a bit. Let&rsquo;s first look at an example input.
The goal is to turn drawings like this one into a 3D mesh, while somehow retaining depth information." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ddr2000.github.io/posts/sketch1-post/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-07-01T09:12:30-04:00" />
<meta property="article:modified_time" content="2024-07-01T09:12:30-04:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Sketch1 Post"/>
<meta name="twitter:description" content="To absolutely no one&rsquo;s surprise I didn&rsquo;t actually go through with updating this page regularly. The good news is I&rsquo;ve been keeping busy with projects.
One of those projects is what I&rsquo;m very creatively calling SketchTo3D. The idea is fairly simple, but we&rsquo;ll talk about the main motivation behind this project in a bit. Let&rsquo;s first look at an example input.
The goal is to turn drawings like this one into a 3D mesh, while somehow retaining depth information."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://ddr2000.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Sketch1 Post",
      "item": "https://ddr2000.github.io/posts/sketch1-post/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Sketch1 Post",
  "name": "Sketch1 Post",
  "description": "To absolutely no one\u0026rsquo;s surprise I didn\u0026rsquo;t actually go through with updating this page regularly. The good news is I\u0026rsquo;ve been keeping busy with projects.\nOne of those projects is what I\u0026rsquo;m very creatively calling SketchTo3D. The idea is fairly simple, but we\u0026rsquo;ll talk about the main motivation behind this project in a bit. Let\u0026rsquo;s first look at an example input.\nThe goal is to turn drawings like this one into a 3D mesh, while somehow retaining depth information.",
  "keywords": [
    
  ],
  "articleBody": "To absolutely no one’s surprise I didn’t actually go through with updating this page regularly. The good news is I’ve been keeping busy with projects.\nOne of those projects is what I’m very creatively calling SketchTo3D. The idea is fairly simple, but we’ll talk about the main motivation behind this project in a bit. Let’s first look at an example input.\nThe goal is to turn drawings like this one into a 3D mesh, while somehow retaining depth information. It may or may not be apparent that the intention with this drawing was to have the bigger square be closer than the smaller square in the back. The algorithm needs to somehow read this intention and also derive the depth in model space.\nThe first step seems simple, we need edge information and/or corner information. However, edge detecting the raw source gives us some chaotic results.\nOpenCV provides a nifty corner detection utility with goodFeaturesToTrack() but it’s going to return every intersection with the rough lines. There are several ways to clean up the edges but none of the ones I thought of initially were good solutions. Simple discarding the shorter lines over some region between corner candidates, generalizing by gradient, could work but might fall apart over other samples. The work around then has to somehow convert human sketches to lines with less character.\nBy using thicker lines, the problem is reframed from detecting and discarding noise to simply thinning one thick line for every edge. I think a package of OpenCV also includes a thinning utility but the theory for Zhang-Suen thinning seems simple enough so lets implement it.\ndef conditionA(img, y, x): x0, y0, x1, y1 = x-1, y-1, x+1, y+1 #[p2,p3,p4,p5,p6,p7,p8,p9] neighbours=[img[y0,x],img[y0,x1],img[y,x1],img[y1,x1],img[y1,x],img[y1,x0],img[y,x0],img[y0,x0]] transitions=0 for i in range(1, len(neighbours)): transitions += (neighbours[i]\u003eneighbours[i-1])*(neighbours[i]-neighbours[i-1]) transitions += (neighbours[0]\u003eneighbours[-1])*(neighbours[0]-neighbours[-1]) return transitions def conditionB(img, y, x): x0, y0, x1, y1 = x-1, y-1, x+1, y+1 return img[y0,x] + img[y0,x1] + img[y,x1] + img[y1,x1] + img[y1,x] + img[y1,x0] + img[y,x0] + img[y0,x0] def thinning(img, rMin, rMax): img = np.where(img\u003e127, 0, 1) while(True): note1=[] for i in range(rMin[0],rMax[0]-1): for j in range(rMin[1], rMax[1]-1): A = conditionA(img, j, i) B = conditionB(img, j, i) c = img[j,i] and (B \u003e= 2) and (B \u003c= 6) and (A == 1) and ((img[j-1, i]==0) or (img[j, i+1]==0) or (img[j+1, i]==0)) and ((img[j, i+1]==0) or (img[j+1, i]==0) or (img[j, i-1])==0) if c: note1.append([j,i]) for p in note1: img[p[0],p[1]]=0 note2 = [] for i in range(rMin[0],rMax[0]-1): for j in range(rMin[1], rMax[1]-1): A = conditionA(img, j, i) B = conditionB(img, j, i) c = img[j,i] and (B \u003e= 2) and (B \u003c= 6) and (A == 1) and ((img[j-1, i]==0) or (img[j, i+1]==0) or (img[j, i-1]==0)) and ((img[j-1, i]==0) or (img[j+1, i]==0) or (img[j, i-1])==0) if c: note2.append([j,i]) for p in note2: img[p[0],p[1]]=0 if(len(note1)==0 or len(note2)==0): break white = (0,0,0) black = (255,255,255) res = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8) # Map binary values to the respective colors res[img == 0] = white res[img == 1] = black img = cv2.cvtColor(res, cv2.COLOR_RGB2GRAY) return img Binarizing the image before passing it onto thinning produces a much cleaner image. Here are the detected points superimposed on the thinned image.\nSo now let’s actually address the main motivation I talked about earlier. In a previous research project, I looked at the viability of using AI images to compose 3D scenes, sort of bypassing the immense compute required to train a model to generate believable 3D scenes directly. One of the pain points of that project was mapping believable depths to each object. A depth mask from some existing model does provide relative depth but how about in this case? This project isolates that problem more so I can think about how best to derive model space depth.\nWith corner information, I’m only generating a flat shape. If samples are made to always be in perspective, a reliable method of deriving depth can be defining vanishing points, and in turn the x-y plane. A z-vector for candidate lines then becomes a simple affair.\nThanks for reading thus far, I’ll update this series with another post after I test some more ideas.\n",
  "wordCount" : "686",
  "inLanguage": "en",
  "datePublished": "2024-07-01T09:12:30-04:00",
  "dateModified": "2024-07-01T09:12:30-04:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://ddr2000.github.io/posts/sketch1-post/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "",
    "logo": {
      "@type": "ImageObject",
      "url": "https://ddr2000.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Sketch1 Post
    </h1>
    <div class="post-meta"><span title='2024-07-01 09:12:30 -0400 EDT'>July 1, 2024</span>

</div>
  </header> 
  <div class="post-content"><p>To absolutely no one&rsquo;s surprise I didn&rsquo;t actually go through with updating this page regularly. The good news is I&rsquo;ve been keeping busy with projects.</p>
<p>One of those projects is what I&rsquo;m very creatively calling SketchTo3D. The idea is fairly simple, but we&rsquo;ll talk about the main motivation behind this project in a bit. Let&rsquo;s first look at an example input.</p>
<figure class="align-center ">
    <img loading="lazy" src="../sketch.jpg#center" width="250"/> 
</figure>

<p>The goal is to turn drawings like this one into a 3D mesh, while somehow retaining depth information. It may or may not be apparent that the intention with this drawing was to have the bigger square be closer than the smaller square in the back. The algorithm needs to somehow read this intention and also derive the depth in model space.</p>
<p>The first step seems simple, we need edge information and/or corner information. However, edge detecting the raw source gives us some chaotic results.</p>
<figure class="align-center ">
    <img loading="lazy" src="../edges_unfiltered.png#center" width="400"/> 
</figure>

<p>OpenCV provides a nifty corner detection utility with goodFeaturesToTrack() but it&rsquo;s going to return every intersection with the rough lines. There are several ways to clean up the edges but none of the ones I thought of initially were good solutions. Simple discarding the shorter lines over some region between corner candidates, generalizing by gradient, could work but might fall apart over other samples. The work around then has to somehow convert human sketches to lines with less character.</p>
<figure class="align-center ">
    <img loading="lazy" src="../edges_unfiltered2.png#center" width="400"/> 
</figure>

<p>By using thicker lines, the problem is reframed from detecting and discarding noise to simply thinning one thick line for every edge. I think a package of OpenCV also includes a thinning utility but the <a href="https://dl.acm.org/doi/pdf/10.1145/357994.358023">theory for Zhang-Suen thinning</a> seems simple enough so lets implement it.</p>
<pre tabindex="0"><code>def conditionA(img, y, x):
    x0, y0, x1, y1 = x-1, y-1, x+1, y+1
    #[p2,p3,p4,p5,p6,p7,p8,p9]
    neighbours=[img[y0,x],img[y0,x1],img[y,x1],img[y1,x1],img[y1,x],img[y1,x0],img[y,x0],img[y0,x0]]
    transitions=0
    for i in range(1, len(neighbours)):
        transitions += (neighbours[i]&gt;neighbours[i-1])*(neighbours[i]-neighbours[i-1])
    transitions += (neighbours[0]&gt;neighbours[-1])*(neighbours[0]-neighbours[-1])
    return transitions

def conditionB(img, y, x):
    x0, y0, x1, y1 = x-1, y-1, x+1, y+1
    return img[y0,x] + img[y0,x1] + img[y,x1] + img[y1,x1] + img[y1,x] + img[y1,x0] + img[y,x0] + img[y0,x0]

def thinning(img, rMin, rMax):
    img = np.where(img&gt;127, 0, 1)
    while(True):
        note1=[]
        for i in range(rMin[0],rMax[0]-1):
            for j in range(rMin[1], rMax[1]-1):
                A = conditionA(img, j, i)
                B = conditionB(img, j, i)
                c = img[j,i] and (B &gt;= 2) and (B &lt;= 6) and (A == 1) and ((img[j-1, i]==0) or (img[j, i+1]==0) or (img[j+1, i]==0)) and ((img[j, i+1]==0) or (img[j+1, i]==0) or (img[j, i-1])==0)
                if c:
                    note1.append([j,i])
        for p in note1:
            img[p[0],p[1]]=0
        note2 = []
        for i in range(rMin[0],rMax[0]-1):
            for j in range(rMin[1], rMax[1]-1):
                A = conditionA(img, j, i)
                B = conditionB(img, j, i)
                c = img[j,i] and (B &gt;= 2) and (B &lt;= 6) and (A == 1) and ((img[j-1, i]==0) or (img[j, i+1]==0) or (img[j, i-1]==0)) and ((img[j-1, i]==0) or (img[j+1, i]==0) or (img[j, i-1])==0)
                if c:
                    note2.append([j,i])
        for p in note2:
            img[p[0],p[1]]=0
        if(len(note1)==0 or len(note2)==0):
            break

    white = (0,0,0)
    black = (255,255,255)

    res = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)

    # Map binary values to the respective colors
    res[img == 0] = white
    res[img == 1] = black

    img = cv2.cvtColor(res, cv2.COLOR_RGB2GRAY)
    return img
</code></pre><p>Binarizing the image before passing it onto thinning produces a much cleaner image. Here are the detected points superimposed on the thinned image.</p>
<figure class="align-center ">
    <img loading="lazy" src="../res_points.jpg#center" width="600"/> 
</figure>

<p>So now let&rsquo;s actually address the main motivation I talked about earlier. In a previous research project, I looked at the viability of using AI images to compose 3D scenes, sort of bypassing the immense compute required to train a model to generate believable 3D scenes directly. One of the pain points of that project was mapping <em>believable</em> depths to each object. A depth mask from some existing model does provide relative depth but how about in this case? This project isolates that problem more so I can think about how best to derive model space depth.</p>
<p>With corner information, I&rsquo;m only generating a flat shape. If samples are made to always be in perspective, a reliable method of deriving depth can be defining vanishing points, and in turn the x-y plane. A z-vector for candidate lines then becomes a simple affair.</p>
<p>Thanks for reading thus far, I&rsquo;ll update this series with another post after I test some more ideas.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="https://ddr2000.github.io/"></a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
